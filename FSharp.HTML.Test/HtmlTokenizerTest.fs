namespace FSharp.HTML

open Xunit
open Xunit.Abstractions
open System.IO

open FSharp.Literals
open FSharp.xUnit
open FslexFsyacc.Runtime

type HtmlTokenizerTest(output:ITestOutputHelper) =
    let show res =
        res
        |> Render.stringify
        |> output.WriteLine

    static let folder = Path.Combine(Dir.TestData,"SeniorTokenizer")

    // generated by `print files` 
    static let source = [
        "cdata.html",    [
            {index= 0;length= 15;value= CData "x<y"};
            {index= 15;length= 2;value= Text "\r\n"}];
        "cdr.html",[
            {index= 0;length= 74;value= TagSelfClosing("cdr:license",["xmlns:cdr","https://www.example.com/cdr/metadata";"name","MIT"])};
            {index= 74;length= 2;value= Text "\r\n"}];
        "comment.html",    [
            {index= 0;length= 42;value= Comment " where is this comment in the DOM? "};
            {index= 42;length= 2;value= Text "\r\n"}];
        "DOCTYPE.html",    [
            {index= 0;length= 15;value= DocType "html"};
            {index= 15;length= 2;value= Text "\r\n"}];
        "link.html",    [
            {index= 0;length= 41;value= TagStart("link",["rel","author license";"href","/about"])};
            {index= 41;length= 2;value= Text "\r\n"}];
        "script.html",    [
            {index= 0;length= 32;value= TagStart("script",["referrerpolicy","origin"])};
            {index= 32;length= 167;value= Text "\r\nfetch('/api/data');    // not fetched with <script>'s referrer policy\r\nimport('./utils.mjs'); // is fetched with <script>'s referrer policy (\"origin\" in this case)\r\n"};
            {index= 199;length= 9;value= TagEnd "script"};
            {index= 208;length= 2;value= Text "\r\n"}];
        "style.html",    [
            {index= 0;length= 7;value= TagStart("style",[])};
            {index= 7;length= 87;value= Text "\r\n body { color: black; background: white; }\r\n em { font-style: normal; color: red; }\r\n"};
            {index= 94;length= 8;value= TagEnd "style"};
            {index= 102;length= 2;value= Text "\r\n"}];
        "template.html",    [
            {index= 0;length= 24;value= TagStart("template",["id","template"])};
            {index= 24;length= 3;value= TagStart("p",[])};
            {index= 27;length= 6;value= Text "Smile!"};
            {index= 33;length= 4;value= TagEnd "p"};
            {index= 37;length= 11;value= TagEnd "template"};
            {index= 48;length= 2;value= Text "\r\n"}];
        "textarea.html",    [
            {index= 0;length= 32;value= TagStart("textarea",["cols","80";"name","comments"])};
            {index= 32;length= 9;value= Text "You rock!"};
            {index= 41;length= 11;value= TagEnd "textarea"};
            {index= 52;length= 2;value= Text "\r\n"}]

        ]
    static let mp = Map.ofList source
    static member data = 
        source
        |> Seq.map (fst>>Array.singleton)

    [<Fact(Skip="get filenames")>]
    member _.``print files``() =
        let files =
            Directory.GetFiles(folder)
            |> Seq.map(fun f -> Path.GetFileName f)
            |> Seq.toList
        show files

    [<Theory;MemberData(nameof HtmlTokenizerTest.data)>]
    member _.``tokenlist test``(f) =
        let path = Path.Combine(folder,f)
        let text = File.ReadAllText(path)
        let y =
            text
            |> Tokenizer.tokenize 
            |> Seq.toList

        show y
        Should.equal y mp.[f]
        
